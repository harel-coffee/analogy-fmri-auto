{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSA Analysis \n",
    "\n",
    "** we end up using searchlight RSA **\n",
    "\n",
    "Comparing BART output with activity in BA10.\n",
    "\n",
    "In this doc we will only work with pymvpa betas. And go more in depth as to what's driving the correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job 750018 (\"ab-clf-searchlight\") has been submitted\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "qsub \\\n",
    "    -o /u/project/monti/njchiang/code/analogy/jobs/output/ \\\n",
    "    -e /u/project/monti/njchiang/code/analogy/jobs/output/ \\\n",
    "    -V -N ab-clf-searchlight \\\n",
    "    -l h_data=8G,h_rt=23:59:59 -pe shared 8 \\\n",
    "    -M ${USER} -m bea \\\n",
    "    /u/project/monti/njchiang/code/analogy/analogy-fmri/analysis/scripts/submit/run_ab_classification.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    ". ~/.bashrc\n",
    "\n",
    "module load fsl\n",
    "cd /u/project/monti/Analysis/Analogy\n",
    "\n",
    "sel=AB\n",
    "\n",
    "\n",
    "for m in BART Word2vec-diff Word2vec-concat # accuracy # rstpostprob79 rstpostprob9 w2vdiff concatword\n",
    "do\n",
    "  echo ${m}\n",
    "  for s in 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16\n",
    "  do\n",
    "    echo sub-${s}\n",
    "      flirt -in analysis/sub-${s}/encoding/sub-${s}_${m}_cope-LSS_${sel}_cv-relation \\\n",
    "      -out analysis/group/encoding/sub-${s}_${m}_${sel}_cv-relation \\\n",
    "      -ref derivatives/standard/MNI152_T1_2mm_brain.nii.gz \\\n",
    "      -applyxfm -init derivatives/sub-${s}/reg/BOLD_template_to_standard.mat\n",
    "    fslmaths analysis/group/encoding/sub-${s}_${m}_${sel}_cv-relation -nan analysis/group/encoding/sub-${s}_${m}_${sel}_cv-relation\n",
    "  done\n",
    "  fslmerge -t analysis/group/encoding/group-ab_${m}_cv-relation.nii.gz analysis/group/encoding/sub*_${m}_${sel}_cv-relation.nii.gz\n",
    "  rm analysis/group/encoding/sub*_${m}_${sel}_cv-relation.nii.gz\n",
    "\n",
    "done\n",
    "\n",
    "\n",
    "#       flirt -in analysis/sub-${s}/encoding/sub-${s}-${m}-cope-LSS_${sel}_cv-relation \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    ". ~/.bashrc\n",
    "module load fsl\n",
    "\n",
    "n=1000\n",
    "cd /u/project/monti/Analysis/Analogy\n",
    "\n",
    "for m in BART Word2vec-diff Word2vec-concat # rstpostprob79 rstpostprob9 w2vdiff concatword\n",
    "do\n",
    "    randomise -i analysis/group/encoding/group-ab_${m}_cv-relation \\\n",
    "      -o analysis/group/encoding/n${n}-ab_${m}_cv-relation \\\n",
    "      -m derivatives/standard/masks/grayMatter \\\n",
    "      -n ${n} -1 -T --uncorrp -v 10\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight RSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job 758783 (\"ab-rsa-searchlight\") has been submitted\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "qsub \\\n",
    "    -o /u/project/monti/njchiang/code/analogy/jobs/output/ \\\n",
    "    -e /u/project/monti/njchiang/code/analogy/jobs/output/ \\\n",
    "    -V -N ab-rsa-searchlight \\\n",
    "    -l h_data=8G,h_rt=23:59:59 -pe shared 8 \\\n",
    "    -M ${USER} -m bea \\\n",
    "    /u/project/monti/njchiang/code/analogy/analogy-fmri/analysis/scripts/submit/run_ab_rsa.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graymatter-bin_mask\n",
      "sub-01\n",
      "sub-02\n",
      "sub-03\n",
      "sub-04\n",
      "sub-05\n",
      "sub-06\n",
      "sub-07\n",
      "sub-08\n",
      "sub-09\n",
      "sub-10\n",
      "sub-11\n",
      "sub-12\n",
      "sub-13\n",
      "sub-14\n",
      "sub-15\n",
      "sub-16\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    ". ~/.bashrc\n",
    "\n",
    "module load fsl\n",
    "cd /u/project/monti/Analysis/Analogy\n",
    "\n",
    "sel=AB\n",
    "\n",
    "m=graymatter-bin_mask\n",
    "echo ${m}\n",
    "mkdir analysis/group/multivariate/rsa/split\n",
    "for s in 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16\n",
    "do\n",
    "  echo sub-${s}\n",
    "#   flirt -in analysis/sub-${s}/multivariate/rsa/sub-${s}_${m}_AB_corr_rsaSearchlight.nii.gz \\\n",
    "  flirt -in analysis/sub-${s}/multivariate/searchlight/sub-${s}_AB-rsa.nii.gz \\\n",
    "  -out analysis/group/multivariate/rsa/sub-${s}_AB-rsa.nii.gz \\\n",
    "  -ref derivatives/standard/MNI152_T1_2mm_brain.nii.gz \\\n",
    "  -applyxfm -init derivatives/sub-${s}/reg/BOLD_template_to_standard.mat\n",
    "  fslmaths analysis/group/multivariate/rsa/sub-${s}_AB-rsa.nii.gz -nan analysis/group/multivariate/rsa/sub-${s}_AB-rsa.nii.gz\n",
    "  fslsplit analysis/group/multivariate/rsa/sub-${s}_AB-rsa.nii.gz analysis/group/multivariate/rsa/split/sub-${s}_\n",
    "done\n",
    "# fslmerge -t analysis/group/multivariate/rsa/group_${m}_AB.nii.gz analysis/group/multivariate/rsa/sub*_${m}_AB_rsaSearchlight.nii.gz\n",
    "\n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_mainrel analysis/group/multivariate/rsa/split/*0000.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_design analysis/group/multivariate/rsa/split/*0001.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_nChars analysis/group/multivariate/rsa/split/*0002.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_humanratings analysis/group/multivariate/rsa/split/*0003.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_typicality analysis/group/multivariate/rsa/split/*0004.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_w2vDiff analysis/group/multivariate/rsa/split/*0005.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_w2vConcat analysis/group/multivariate/rsa/split/*0006.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_BART9 analysis/group/multivariate/rsa/split/*0007.nii.gz \n",
    "fslmerge -t analysis/group/multivariate/rsa/pearson/group_AB_BART79 analysis/group/multivariate/rsa/split/*0008.nii.gz \n",
    "# fslmerge -t analysis/group/multivariate/rsa/group_gm_AB_designAndBART9 analysis/group/multivariate/rsa/split/*0006.nii.gz \n",
    "# fslmerge -t analysis/group/multivariate/rsa/group_gm_AB_designAndw2vDiff analysis/group/multivariate/rsa/split/*0007.nii.gz \n",
    "# fslmerge -t analysis/group/multivariate/rsa/group_gm_AB_designAndw2vConcat analysis/group/multivariate/rsa/split/*0008.nii.gz \n",
    "# fslmerge -t analysis/group/multivariate/rsa/group_gm_AB_BART9Andw2vConcat analysis/group/multivariate/rsa/split/*0009.nii.gz \n",
    "\n",
    "rm analysis/group/multivariate/rsa/sub*_AB-rsa.nii.gz\n",
    "rm -r analysis/group/multivariate/rsa/split\n",
    "\n",
    "\n",
    "#       flirt -in analysis/sub-${s}/encoding/sub-${s}-${m}-cope-LSS_${sel}_cv-relation \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    ". ~/.bashrc\n",
    "module load fsl\n",
    "\n",
    "n=1000\n",
    "cd /u/project/monti/Analysis/Analogy\n",
    "\n",
    "for m in nChars humanratings typicality mainrel design w2vConcat w2vDiff BART79 # rstpostprob79 rstpostprob9 w2vdiff concatword\n",
    "do\n",
    "    randomise -i analysis/group/multivariate/rsa/pearson/group_AB_${m} \\\n",
    "      -o analysis/group/multivariate/rsa/pearson/n${n}-AB_${m} \\\n",
    "      -m derivatives/standard/masks/grayMatter \\\n",
    "      -n ${n} -1 -T --uncorrp -v 10\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/n/njchiang/.conda/envs/fmri/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON config from config/analyses.json\n",
      "Loading JSON config from config/contrasts.json\n",
      "Loading label file from: labels/trialorder_rsa_absorted.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "from datetime import datetime\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from analysis.fmri.analogy_utils import analysisSettings, contrastSettings, projectSettings, \\\n",
    "    PATHS, order, \\\n",
    "    pu, pa, pv, rsa, \\\n",
    "    compile_models, save_rois, load_rois, load_betas\n",
    "\n",
    "paths = PATHS\n",
    "\n",
    "class CVSearchlight:\n",
    "    def __init__(self, sub, mask_file=None, settings=analysisSettings[\"searchlight\"], phase=\"AB\", logger=None, phase_equals=True, phase_val=1):\n",
    "        self.logger = logger\n",
    "        self.sub = sub\n",
    "        self.phase = phase\n",
    "        self.target = \"{}MainRel\".format(phase.upper())\n",
    "        self.mask = pu.load_img(mask_file, logger=logger) if mask_file else None\n",
    "        self.fmri_data, self.labels, self.bg_image = load_betas(projectSettings, sub, t=\"cope-LSS\", logger=logger)\n",
    "        self.select_data(phase, phase_equals, phase_val)\n",
    "        self.init_sl(settings)\n",
    "        self.outpath = os.path.join(paths[\"root\"], \"analysis\", sub, \"multivariate\", \"searchlight\", \"mvpa\", \"{}_{}-cvsl.nii.gz\".format(sub, phase))\n",
    "\n",
    "    def select_data(self, phase=\"AB\", equals=True, val=1):\n",
    "        if equals:\n",
    "            self.selector = self.labels[self.labels[phase] == val]\n",
    "        else:\n",
    "            self.selector = self.labels[self.labels[phase] != val]\n",
    "        self.fmri_data = pu.index_img(self.fmri_data, self.selector.index)\n",
    "\n",
    "    def init_sl(self, settings):\n",
    "        settings[\"estimator\"] = Pipeline(steps=[  # (\n",
    "            # \"variance_threshold\", VarianceThreshold()),\n",
    "            (\"scaling\", StandardScaler()),\n",
    "        #            (\"feature_select\", SelectPercentile(f_classif, percentile=20)),\n",
    "        #            (\"feature_select\", SelectKBest(f_classif, k=100)),\n",
    "            (\"svm\", LinearSVC(C=0.05))\n",
    "        #            (\"plr\", LogisticRegression(C=0.05, penalty=\"l1\", tol=0.01))\n",
    "        ])\n",
    "        self.cv = LeaveOneGroupOut()\n",
    "        self.sl_options = settings\n",
    "\n",
    "    def run(self, **unused):\n",
    "        result = pa.searchlight(self.fmri_data, self.selector[self.target],\n",
    "                                m=self.mask, cv=self.cv,\n",
    "                                groups=self.selector['chunks'], write=False,\n",
    "                                logger=self.logger, **self.sl_options)\n",
    "        pu.data_to_img(result.scores_, self.bg_image, logger=self.logger).to_filename(self.outpath)\n",
    "        return result\n",
    "    \n",
    "class RSASearchlight(CVSearchlight):\n",
    "    def __init__(self, sub, mask_file=None, settings=analysisSettings[\"searchlight\"], phase=\"AB\", logger=None, phase_equals=True, phase_val=1):\n",
    "        super(RSASearchlight, self).__init__(sub, mask_file, settings=settings, phase=phase, logger=logger, phase_equals=phase_equals, phase_val=phase_val)\n",
    "        self.outpath = os.path.join(paths[\"root\"], \"analysis\", sub, \"multivariate\", \"searchlight\", \"{}_{}-rsa.nii.gz\".format(sub, phase))\n",
    "    def select_data(self, phase=\"AB\", equals=True, val=1):\n",
    "        # will be a little more complex\n",
    "        if equals:\n",
    "            self.selector = self.labels[self.labels[phase] == val].sort_values([\"SubRel\", \"TrialTag\"])\n",
    "        else:\n",
    "            self.selector = self.labels[self.labels[phase] != val]\n",
    "        self.fmri_data = pu.index_img(self.fmri_data, self.selector.index)\n",
    "\n",
    "    def init_sl(self, settings):\n",
    "        settings[\"rdm_metric\"] = \"correlation\"\n",
    "        self.sl_options = settings\n",
    "\n",
    "    def run(self, modelrdms):\n",
    "        result = pa.searchlight_rsa(\n",
    "            self.fmri_data, modelrdms,\n",
    "            m=self.mask, write=False,\n",
    "            logger=self.logger, **self.sl_options)\n",
    "        pu.data_to_img(result.scores_, self.bg_image, logger=self.logger).to_filename(self.outpath)\n",
    "        return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/masks/dfc-left-ba10_mask.nii.gz\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-01_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-02_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-03_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-04_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-05_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-06_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-07_events.csv\n",
      "centering image\n",
      "Loading label file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/func/sub-01_task-analogy_run-08_events.csv\n",
      "Concatenating 8 images\n",
      "Reading file from: /u/project/monti/Analysis/Analogy/derivatives/sub-01/reg/BOLD_template.nii.gz\n",
      "Slicing image\n"
     ]
    }
   ],
   "source": [
    "logger=None\n",
    "phase = \"AB\"\n",
    "sub = \"sub-01\"\n",
    "roi = \"dfc-left-ba10_mask\"\n",
    "# roi = \"graymatter-bin_mask\"\n",
    "mask_file = os.path.join(paths[\"root\"], \"derivatives\", sub, \"masks\", \"{}.nii.gz\".format(roi))\n",
    "\n",
    "sl = RSASearchlight(sub, mask_file, phase=phase, settings=analysisSettings[\"searchlight\"], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/u/project/monti/Analysis/Analogy/analysis/sub-01/multivariate/searchlight/sub-01_AB-rsa.nii.gz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading label file from: /u/project/monti/Analysis/Analogy/code/analogy-fmri/labels/raw_models.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 41328)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis.fmri.analogy_rsa import get_model_rdms\n",
    "\n",
    "modelnames = [\n",
    "            \"mainrel\", \"rel\", \"numchar\", \"humanratings\", \"typicality\",\n",
    "            \"w2vdiff\", \"concatword\", \"rstpostprob9\", \"rstpostprob79\"]# , ]\n",
    "raw_models_df = pu.load_labels(os.path.join(paths[\"code\"], \"labels/raw_models.csv\"))\n",
    "model_rdms = get_model_rdms(raw_models_df, modelnames)\n",
    "modelrdms = model_rdms[(model_rdms.type == \"full\")].dropna(axis=1).values[:, 2:].astype(np.float64)\n",
    "\n",
    "modelrdms[0][1] = np.nan  # see if we can replicate error\n",
    "modelrdms[1] = np.zeros(modelrdms[1].shape)\n",
    "modelrdms.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sl.fmri_data.get_data()[1:3, 1:3, 1:3, :].transpose([3, 0, 1, 2]).reshape(288, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/n/njchiang/.conda/envs/fmri/lib/python3.7/site-packages/numpy/lib/function_base.py:2530: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/u/home/n/njchiang/.conda/envs/fmri/lib/python3.7/site-packages/numpy/lib/function_base.py:2531: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/u/home/n/njchiang/.conda/envs/fmri/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/u/home/n/njchiang/.conda/envs/fmri/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/u/home/n/njchiang/.conda/envs/fmri/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,  0.0596707 ,\n",
       "       -0.02336561,  0.00889081,  0.07877774,  0.08815722,  0.09902996,\n",
       "        0.02915433,  0.07979786,  0.24782568,  0.25317203,  0.22416953,\n",
       "       -0.00104395,  0.00098889,  0.10142633,  0.14304838,  0.34333765,\n",
       "        0.14764529,  0.2062172 ,  0.15811788,  0.14853567,  0.860852  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_rdm = rsa.rdm(x, metric=\"correlation\")\n",
    "1 - rsa.rdm(np.vstack([roi_rdm, modelrdms]).astype(np.float64), metric=\"spearman\", return_p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chk_asarray(a, axis):\n",
    "    if axis is None:\n",
    "        a = np.ravel(a)\n",
    "        outaxis = 0\n",
    "    else:\n",
    "        a = np.asarray(a)\n",
    "        outaxis = axis\n",
    "\n",
    "    if a.ndim == 0:\n",
    "        a = np.atleast_1d(a)\n",
    "\n",
    "    return a, outaxis\n",
    "\n",
    "\n",
    "def _chk2_asarray(a, b, axis):\n",
    "    if axis is None:\n",
    "        a = np.ravel(a)\n",
    "        b = np.ravel(b)\n",
    "        outaxis = 0\n",
    "    else:\n",
    "        a = np.asarray(a)\n",
    "        b = np.asarray(b)\n",
    "        outaxis = axis\n",
    "\n",
    "    if a.ndim == 0:\n",
    "        a = np.atleast_1d(a)\n",
    "    if b.ndim == 0:\n",
    "        b = np.atleast_1d(b)\n",
    "\n",
    "    return a, b, outaxis\n",
    "\n",
    "\n",
    "def _contains_nan(a, nan_policy='propagate'):\n",
    "    policies = ['propagate', 'raise', 'omit']\n",
    "    if nan_policy not in policies:\n",
    "        raise ValueError(\"nan_policy must be one of {%s}\" %\n",
    "                         ', '.join(\"'%s'\" % s for s in policies))\n",
    "    try:\n",
    "        # Calling np.sum to avoid creating a huge array into memory\n",
    "        # e.g. np.isnan(a).any()\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            contains_nan = np.isnan(np.sum(a))\n",
    "    except TypeError:\n",
    "        # This can happen when attempting to sum things which are not\n",
    "        # numbers (e.g. as in the function `mode`). Try an alternative method:\n",
    "        try:\n",
    "            contains_nan = np.nan in set(a.ravel())\n",
    "        except TypeError:\n",
    "            # Don't know what to do. Fall back to omitting nan values and\n",
    "            # issue a warning.\n",
    "            contains_nan = False\n",
    "            nan_policy = 'omit'\n",
    "            warnings.warn(\"The input array could not be properly checked for nan \"\n",
    "                          \"values. nan values will be ignored.\", RuntimeWarning)\n",
    "\n",
    "    if contains_nan and nan_policy == 'raise':\n",
    "        raise ValueError(\"The input contains nan values\")\n",
    "\n",
    "    return (contains_nan, nan_policy)\n",
    "\n",
    "from scipy.stats import mstats_basic\n",
    "from scipy.stats import rankdata, distributions\n",
    "import pdb\n",
    "\n",
    "def spearmanr(a, b=None, axis=0, nan_policy='propagate'):\n",
    "    \"\"\"\n",
    "    Calculate a Spearman rank-order correlation coefficient and the p-value\n",
    "    to test for non-correlation.\n",
    "    The Spearman correlation is a nonparametric measure of the monotonicity\n",
    "    of the relationship between two datasets. Unlike the Pearson correlation,\n",
    "    the Spearman correlation does not assume that both datasets are normally\n",
    "    distributed. Like other correlation coefficients, this one varies\n",
    "    between -1 and +1 with 0 implying no correlation. Correlations of -1 or\n",
    "    +1 imply an exact monotonic relationship. Positive correlations imply that\n",
    "    as x increases, so does y. Negative correlations imply that as x\n",
    "    increases, y decreases.\n",
    "    The p-value roughly indicates the probability of an uncorrelated system\n",
    "    producing datasets that have a Spearman correlation at least as extreme\n",
    "    as the one computed from these datasets. The p-values are not entirely\n",
    "    reliable but are probably reasonable for datasets larger than 500 or so.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b : 1D or 2D array_like, b is optional\n",
    "        One or two 1-D or 2-D arrays containing multiple variables and\n",
    "        observations. When these are 1-D, each represents a vector of\n",
    "        observations of a single variable. For the behavior in the 2-D case,\n",
    "        see under ``axis``, below.\n",
    "        Both arrays need to have the same length in the ``axis`` dimension.\n",
    "    axis : int or None, optional\n",
    "        If axis=0 (default), then each column represents a variable, with\n",
    "        observations in the rows. If axis=1, the relationship is transposed:\n",
    "        each row represents a variable, while the columns contain observations.\n",
    "        If axis=None, then both arrays will be raveled.\n",
    "    nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
    "        Defines how to handle when input contains nan. 'propagate' returns nan,\n",
    "        'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
    "        values. Default is 'propagate'.\n",
    "    Returns\n",
    "    -------\n",
    "    correlation : float or ndarray (2-D square)\n",
    "        Spearman correlation matrix or correlation coefficient (if only 2\n",
    "        variables are given as parameters. Correlation matrix is square with\n",
    "        length equal to total number of variables (columns or rows) in ``a``\n",
    "        and ``b`` combined.\n",
    "    pvalue : float\n",
    "        The two-sided p-value for a hypothesis test whose null hypothesis is\n",
    "        that two sets of data are uncorrelated, has same dimension as rho.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
    "       Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
    "       York. 2000.\n",
    "       Section  14.7\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from scipy import stats\n",
    "    >>> stats.spearmanr([1,2,3,4,5], [5,6,7,8,7])\n",
    "    (0.82078268166812329, 0.088587005313543798)\n",
    "    >>> np.random.seed(1234321)\n",
    "    >>> x2n = np.random.randn(100, 2)\n",
    "    >>> y2n = np.random.randn(100, 2)\n",
    "    >>> stats.spearmanr(x2n)\n",
    "    (0.059969996999699973, 0.55338590803773591)\n",
    "    >>> stats.spearmanr(x2n[:,0], x2n[:,1])\n",
    "    (0.059969996999699973, 0.55338590803773591)\n",
    "    >>> rho, pval = stats.spearmanr(x2n, y2n)\n",
    "    >>> rho\n",
    "    array([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],\n",
    "           [ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],\n",
    "           [ 0.18569457,  0.110003  ,  1.        ,  0.03488749],\n",
    "           [ 0.06258626,  0.02534653,  0.03488749,  1.        ]])\n",
    "    >>> pval\n",
    "    array([[ 0.        ,  0.55338591,  0.06435364,  0.53617935],\n",
    "           [ 0.55338591,  0.        ,  0.27592895,  0.80234077],\n",
    "           [ 0.06435364,  0.27592895,  0.        ,  0.73039992],\n",
    "           [ 0.53617935,  0.80234077,  0.73039992,  0.        ]])\n",
    "    >>> rho, pval = stats.spearmanr(x2n.T, y2n.T, axis=1)\n",
    "    >>> rho\n",
    "    array([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],\n",
    "           [ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],\n",
    "           [ 0.18569457,  0.110003  ,  1.        ,  0.03488749],\n",
    "           [ 0.06258626,  0.02534653,  0.03488749,  1.        ]])\n",
    "    >>> stats.spearmanr(x2n, y2n, axis=None)\n",
    "    (0.10816770419260482, 0.1273562188027364)\n",
    "    >>> stats.spearmanr(x2n.ravel(), y2n.ravel())\n",
    "    (0.10816770419260482, 0.1273562188027364)\n",
    "    >>> xint = np.random.randint(10, size=(100, 2))\n",
    "    >>> stats.spearmanr(xint)\n",
    "    (0.052760927029710199, 0.60213045837062351)\n",
    "    \"\"\"\n",
    "    a, axisout = _chk_asarray(a, axis)\n",
    "    x = a\n",
    "    if a.ndim > 2:\n",
    "        raise ValueError(\"spearmanr only handles 1-D or 2-D arrays\")\n",
    "\n",
    "    if b is None:\n",
    "        if a.ndim < 2:\n",
    "            raise ValueError(\"`spearmanr` needs at least 2 variables to compare\")\n",
    "    else:\n",
    "        # Concatenate a and b, so that we now only have to handle the case\n",
    "        # of a 2-D `a`.\n",
    "        b, _ = _chk_asarray(b, axis)\n",
    "        if axisout == 0:\n",
    "            a = np.column_stack((a, b))\n",
    "        else:\n",
    "            a = np.row_stack((a, b))\n",
    "\n",
    "    n_vars = a.shape[1 - axisout]\n",
    "    n_obs = a.shape[axisout]\n",
    "    if n_obs <= 1:\n",
    "        # Handle empty arrays or single observations.\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "    a_contains_nan, nan_policy = _contains_nan(a, nan_policy)\n",
    "    variable_has_nan = np.zeros(n_vars, dtype=bool)\n",
    "    if a_contains_nan:\n",
    "        if nan_policy == 'omit':\n",
    "            return mstats_basic.spearmanr(a, axis=axis, nan_policy=nan_policy)\n",
    "        elif nan_policy == 'propagate':\n",
    "            if a.ndim == 1 or n_vars <= 2:\n",
    "                return (np.nan, np.nan)\n",
    "            else:\n",
    "                # Keep track of variables with NaNs, set the outputs to NaN\n",
    "                # only for those variables\n",
    "                variable_has_nan = np.isnan(a).sum(axis=axisout).astype(np.bool)\n",
    "\n",
    "    a_ranked = np.apply_along_axis(rankdata, axisout, a)\n",
    "    rs = np.corrcoef(a_ranked, rowvar=axisout)\n",
    "    dof = n_obs - 2  # degrees of freedom\n",
    "\n",
    "    # rs can have elements equal to 1, so avoid zero division warnings\n",
    "    olderr = np.seterr(divide='ignore')\n",
    "    try:\n",
    "        # clip the small negative values possibly caused by rounding\n",
    "        # errors before taking the square root\n",
    "        t = rs * np.sqrt((dof/((rs+1.0)*(1.0-rs))).clip(0))\n",
    "    finally:\n",
    "        np.seterr(**olderr)\n",
    "\n",
    "    prob = 2 * distributions.t.sf(np.abs(t), dof)\n",
    "#     pdb.set_trace()\n",
    "    # For backwards compatibility, return scalars when comparing 2 columns\n",
    "    if rs.shape == (2, 2):\n",
    "        return (rs[1, 0], prob[1, 0])\n",
    "    else:\n",
    "        rs[variable_has_nan, :] = np.nan\n",
    "        rs[:, variable_has_nan] = np.nan\n",
    "        return (rs, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 0.00000000e+000,             nan,\n",
       "        1.51047808e-005, 0.00000000e+000, 2.55946331e-007,\n",
       "        6.22709844e-002, 9.87735531e-187, 1.24488616e-002,\n",
       "        6.92088071e-012],\n",
       "       [0.00000000e+000, 0.00000000e+000,             nan,\n",
       "        1.28098786e-032, 0.00000000e+000, 1.61663967e-002,\n",
       "        1.35147258e-032, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000],\n",
       "       [            nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan],\n",
       "       [1.51047808e-005, 1.28098786e-032,             nan,\n",
       "        0.00000000e+000, 6.39749074e-034, 2.02847410e-006,\n",
       "        7.06970451e-002, 6.78051603e-058, 4.29500564e-072,\n",
       "        1.43522217e-090],\n",
       "       [0.00000000e+000, 0.00000000e+000,             nan,\n",
       "        6.39749074e-034, 0.00000000e+000, 3.06742351e-009,\n",
       "        2.31675272e-059, 0.00000000e+000, 0.00000000e+000,\n",
       "        0.00000000e+000],\n",
       "       [2.55946331e-007, 1.61663967e-002,             nan,\n",
       "        2.02847410e-006, 3.06742351e-009, 0.00000000e+000,\n",
       "        8.31933952e-001, 8.40676307e-001, 6.19567789e-095,\n",
       "        7.99910219e-188],\n",
       "       [6.22709844e-002, 1.35147258e-032,             nan,\n",
       "        7.06970451e-002, 2.31675272e-059, 8.31933952e-001,\n",
       "        0.00000000e+000, 0.00000000e+000, 4.35334033e-200,\n",
       "        0.00000000e+000],\n",
       "       [9.87735531e-187, 0.00000000e+000,             nan,\n",
       "        6.78051603e-058, 0.00000000e+000, 8.40676307e-001,\n",
       "        0.00000000e+000, 0.00000000e+000, 1.53172489e-229,\n",
       "        1.64672395e-202],\n",
       "       [1.24488616e-002, 0.00000000e+000,             nan,\n",
       "        4.29500564e-072, 0.00000000e+000, 6.19567789e-095,\n",
       "        4.35334033e-200, 1.53172489e-229, 0.00000000e+000,\n",
       "        0.00000000e+000],\n",
       "       [6.92088071e-012, 0.00000000e+000,             nan,\n",
       "        1.43522217e-090, 0.00000000e+000, 7.99910219e-188,\n",
       "        0.00000000e+000, 1.64672395e-202, 0.00000000e+000,\n",
       "        0.00000000e+000]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(np.vstack([roi_rdm, modelrdms]).astype(np.float64), axis=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting searchlight at 2019-09-04 22:21:53.065818\n",
      "searchlight params: {'radius': 5, 'n_jobs': -1, 'verbose': 1, 'rdm_metric': 'correlation'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7cb07cbcc8d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mslargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"modelrdms\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodelrdms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mslargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-7277ba51cb42>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, modelrdms)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmri_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelrdms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             logger=self.logger, **self.sl_options)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/project/monti/Analysis/Analogy/code/analogy-fmri/analysis/fmri/utils/fmri_core/analysis.py\u001b[0m in \u001b[0;36msearchlight_rsa\u001b[0;34m(x, y, m, write, logger, **searchlight_args)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mwrite_to_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"searchlight params: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchlight_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRSASearchlight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msearchlight_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mwrite_to_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Searchlight ended at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/project/monti/Analysis/Analogy/code/analogy-fmri/analysis/fmri/utils/fmri_core/rsa_searchlight.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, imgs, y)\u001b[0m\n\u001b[1;32m    252\u001b[0m         X, A = _apply_mask_and_get_affinity(\n\u001b[1;32m    253\u001b[0m             \u001b[0mprocess_mask_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             mask_img=self.mask_img)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         scores = search_light(X, y, A, metric=self.metric,\n",
      "\u001b[0;32m~/.conda/envs/fmri/lib/python3.7/site-packages/nilearn/input_data/nifti_spheres_masker.py\u001b[0m in \u001b[0;36m_apply_mask_and_get_affinity\u001b[0;34m(seeds, niimg, radius, allow_overlap, mask_img)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmask_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_mask_fmri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fmri/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36m_apply_mask_fmri\u001b[0;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     series = _utils.as_ndarray(series, dtype=dtype, order=\"C\",\n\u001b[0;32m--> 749\u001b[0;31m                                copy=True)\n\u001b[0m\u001b[1;32m    750\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mimgs_img\u001b[0m  \u001b[0;31m# frees a lot of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fmri/lib/python3.7/site-packages/nilearn/_utils/numpy_conversions.py\u001b[0m in \u001b[0;36mas_ndarray\u001b[0;34m(arr, copy, dtype, order)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# In the present cas, np.may_share_memory result is always reliable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fmri/lib/python3.7/site-packages/nilearn/_utils/numpy_conversions.py\u001b[0m in \u001b[0;36m_asarray\u001b[0;34m(arr, dtype, order)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fmri/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slargs = {\"modelrdms\": modelrdms}\n",
    "result = sl.run(**slargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0. , 1.5, 1.5],\n",
       "        [1.5, 0. , 1.5],\n",
       "        [1.5, 1.5, 0. ]]), array([[0.        , 0.66666667, 0.66666667],\n",
       "        [0.66666667, 0.        , 0.66666667],\n",
       "        [0.66666667, 0.66666667, 0.        ]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsa.spearman_distance(np.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.11022302e-16, 8.73567357e-01, 9.52499250e-01],\n",
       "        [8.73567357e-01, 1.11022302e-16, 1.10082208e+00],\n",
       "        [9.52499250e-01, 1.10082208e+00, 1.11022302e-16]]),\n",
       " array([[0.        , 0.21003558, 0.63885483],\n",
       "        [0.21003558, 0.        , 0.31823524],\n",
       "        [0.63885483, 0.31823524, 0.        ]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(3, 100)\n",
    "rsa.spearman_distance(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compbio",
   "language": "python",
   "name": "compbio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
